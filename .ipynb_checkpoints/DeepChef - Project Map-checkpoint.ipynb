{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb6d58d",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">**Project DeepChef:**</span>\n",
    "### Performing data analysis, ML and NLP on recipes and reviews\n",
    "* Data on over 500,000 recipes and 1,400,000 reviews from Food.com\n",
    "* Link to the dataset: https://www.kaggle.com/datasets/irkaal/foodcom-recipes-and-reviews\n",
    "\n",
    "<span style=\"color:red\">**NOTE:**</span> My aim is to get all of the following done, but priority will be given to the ones that come earlier in each section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fef20c",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Section I: Classical Data Analysis and ML</span>\n",
    "\n",
    "\n",
    "In the classical section of the project, I will do 3 ML projects.\n",
    "\n",
    "\n",
    "### Part 0: Basic Data Cleaning\n",
    "The first step is to do some basic data cleaning and rid of all the columns that won't be of any use acrross any of the projects going forward, and add some useful columns to the dataset based on the existing ones that will come handy in both Data Analysis and ML/NLP.\n",
    "\n",
    "* **Drop:**\n",
    "['Name', 'AuthorName', 'CookTime', 'PrepTime', 'TotalTime', 'DatePublished', 'Description', 'Images', 'ReviewCount']\n",
    "\n",
    "* **Add:**\n",
    "['TotalMinutes', 'YearPublished', 'MonthPublished', 'DayPublished', 'HourPublished']\n",
    "\n",
    "* **Replace:**\n",
    "['RecipeIngredientQuantities', 'RecipeIngredientParts'] with ones scraped from food.com froms scratch.\n",
    "\n",
    "**Save:**\n",
    "BasicCleanData.parquet\n",
    "\n",
    "We can perform classical data analysis on BasicCleanData.pkl\n",
    "\n",
    "\n",
    "### Part 1: Predicting AggregatedRating:\n",
    "In this part of the project, I aim at predicting the `AggregatedRating` of the rows that miss its values using otehr features, with the help of rows that have values for `AggregatedRating`. \n",
    "\n",
    "* **Drop (from BasicCleanData.pkl):**\n",
    "['RecipeId', 'AuthorId', 'Description', 'Images', 'ReviewCount', 'RecipeServings', 'RecipeYield', 'RecipeInstructions', 'RecipeServings', 'RecipeYield', 'RecipeInstructions', 'url']\n",
    "\n",
    "* **Save:**\n",
    "CleanDataRatingPredict.parquet\n",
    "\n",
    "\n",
    "### Part 2: Predicting RecipeServings and RecipeYield\n",
    "For those recipes that miss these, we can determine how many people a recipe serves, and how many of the thing it yields, using recipes that have these values. For example, for the recipes that have `Serves` values, since this seems to be a function of `RecipeIngredientParts` and `RecipeIngredientQuants`, we can train a model with the independent variables consisting of these two columns, and the target variable beging `Serves`.\n",
    "\n",
    "We can then apply this model to determine the missing `Serves` values of the other recipes.\n",
    "\n",
    "The model should probably be based on KNN or K-Means algorithms. We want to assign a `Serves` value to a recipe based on the `Serves` value of the recipes with *similar* `RecipeIngredientParts` and `RecipeIngredientQuants`.\n",
    "\n",
    "For this, we should encode the items in `RecipeIngredientParts` into numbers, and then train the model on pairs of (a,b), where a is the quantity of an item and b is its numerical representation, to predict the servings number.\n",
    "\n",
    "* **Drop:**\n",
    "['RecipeId', 'Name', 'AuthorId', 'AuthorName', 'CookTime', 'PrepTime', 'TotalTime', 'DatePublished', 'Description', 'Images', 'RecipeCategory', 'Keywords', 'AggregatedRating', 'ReviewCount', 'Calories', 'FatContent', 'SaturatedFatContent', 'CholesterolContent', 'SodiumContent', 'CarbohydrateContent', 'FiberContent', 'SugarContent', 'ProteinContent', 'RecipeServings', 'RecipeYield', 'RecipeInstructions', 'url']\n",
    "\n",
    "* **Save:**\n",
    "CleanDataServeYield.parquet\n",
    "\n",
    "### Part 3: Recipe Recommender\n",
    "In the last part of Section, I'll create a recommedner system based on seevral feratures in the recipes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c1b7f",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Section II: Advanced NLP</span>\n",
    "\n",
    "In this section of the project, I'll be performing advanced NLP on the text data available in the recipes and reviews datasets.\n",
    "\n",
    "### Part 0: Predicting AggregatedRating Based on Reviews\n",
    "\n",
    "Extract Sentiment scores for each recipe, using the Reviews data set\n",
    "\n",
    "* **Drop (from BasicCleanData.pkl):**\n",
    "['Description', 'Images', 'RecipeServings', 'RecipeYield', 'RecipeInstructions','RecipeServings', 'RecipeYield', 'RecipeInstructions', 'url']\n",
    "\n",
    "* **Join:**\n",
    "Reviews dataset\n",
    "\n",
    "* **Drop:**\n",
    "\n",
    "* **Save:**\n",
    "CleanDataRatingPredReview.pkl\n",
    "\n",
    "### Part 1: Topic Modeling\n",
    "\n",
    "Perform topic-modeling on recipes and make clusters of recipes based on their similarities\n",
    "\n",
    "### Part 3: Semantic Search\n",
    "\n",
    "Enable semantic search on the recipes database\n",
    "\n",
    "### Part 4: Recipe Generation\n",
    "\n",
    "Fine-tune Large Language Models for the purpose of recipe generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738741b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
